{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25497a04-fd26-41bc-826e-d68b64c5144d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Dict, List\n",
    "from tavily import TavilyClient\n",
    "import google.generativeai as genai\n",
    "from langgraph.graph import StateGraph, END\n",
    "from dotenv import load_dotenv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa3ce27d-6ccc-4a5f-b9a4-d3c3289e352f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d0725f2-09b8-4b75-a444-5d3f6b4369f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Google's Generative AI with the API key from environment variables\n",
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cafccd98-aa3a-4c1c-b0de-7399e894893b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Gemini 1.5 Pro model from Google's Generative AI\n",
    "llm = genai.GenerativeModel('gemini-1.5-pro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26eaabb7-184b-4fc7-b303-92d6c9fb3dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TavilyClient with the API key from environment variables\n",
    "tavily = TavilyClient(api_key=os.getenv(\"TAVILY_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8bfc136c-2f81-40cd-8bd8-92195d8e7b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the research agent function\n",
    "def research_agent(state: Dict):\n",
    "    # Perform a search using Tavily with the query from the state\n",
    "    response = tavily.search(state[\"query\"])\n",
    "    # Return the search results along with the existing state\n",
    "    return {\n",
    "        \"research_results\": response.get('results', []),\n",
    "        \"drafted_answer\": state[\"drafted_answer\"],\n",
    "        \"query\": state[\"query\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0294055-30aa-44ed-ad5b-f726c53a79b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the drafting agent function\n",
    "def drafting_agent(state: Dict):\n",
    "    # Combine the content from all research results into a single context string\n",
    "    context = \"\\n\".join([res.get('content', '') for res in state[\"research_results\"]])\n",
    "    # Generate a summary of the context using the Gemini model\n",
    "    response = llm.generate_content(f\"Summarize: {context}\")\n",
    "    # Return the research results, the drafted answer, and the query\n",
    "    return {\n",
    "        \"research_results\": state[\"research_results\"],\n",
    "        \"drafted_answer\": response.text,\n",
    "        \"query\": state[\"query\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11ec2db7-396f-4075-8c14-43dce859e045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to build the workflow\n",
    "def build_workflow():\n",
    "    workflow = StateGraph(dict)\n",
    "    workflow.add_node(\"research\", research_agent)\n",
    "    workflow.add_node(\"drafting\", drafting_agent)\n",
    "    workflow.add_edge(\"research\", \"drafting\")\n",
    "    workflow.add_edge(\"drafting\", END)\n",
    "    workflow.set_entry_point(\"research\")\n",
    "    return workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17824587-5d0f-4a40-adc1-d3d0aeb34d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to run the research system\n",
    "def run_research_system(query: str):\n",
    "    # Build the workflow\n",
    "    workflow = build_workflow()\n",
    "    # Invoke the workflow with the initial state\n",
    "    result = workflow.invoke({\n",
    "        \"research_results\": [],\n",
    "        \"drafted_answer\": \"\",\n",
    "        \"query\": query\n",
    "    })\n",
    "    # Return the drafted answer from the workflow result\n",
    "    return result[\"drafted_answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ae0f73a-22b5-4556-8d79-0b8bf6a97f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI is significantly impacting cybersecurity, with CISOs recognizing its influence and organizations increasingly relying on it for defense.  The year 2025 is predicted to be a pivotal year for AI in cybersecurity, bringing both opportunities and challenges.  AI is transforming cybersecurity operations, particularly in threat detection and incident response, but its integration also necessitates new security measures.  Cybersecurity providers who understand, embrace, and offer AI-powered solutions, including securing AI implementations themselves, will have a competitive edge.  This includes expanding AI's role in cybersecurity beyond SecOps to areas like cloud and endpoint security.  Nationally and internationally, managing the cybersecurity implications of AI is crucial for cyber-resilience as AI becomes more integrated into critical infrastructure and society.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Main entry point of the script\n",
    "if __name__ == \"__main__\":\n",
    "    # Run the research system with a sample query\n",
    "    response = run_research_system(\"Impact of AI on cybersecurity in points\")\n",
    "    # Print the response\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918df8d3-273c-48d2-8ce7-3152c06c4c48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
